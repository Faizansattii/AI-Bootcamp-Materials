{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Week 10 - Day 1: Computer Vision & CNN Basics\n",
    "## Visual Journey into Convolutional Neural Networks\n",
    "\n",
    "### Today's Learning Goals:\n",
    "- âœ… Understand how images are represented as numbers\n",
    "- âœ… Visualize RGB channels and pixel grids\n",
    "- âœ… Master the convolution operation step-by-step\n",
    "- âœ… Apply different kernels (edge detection, blur, sharpen)\n",
    "- âœ… Experiment with padding and stride effects\n",
    "- âœ… Calculate output dimensions\n",
    "- âœ… Visualize feature maps from real CNNs\n",
    "- âœ… Build your first convolutional layer in PyTorch\n",
    "\n",
    "---\n",
    "\n",
    "**Let's make computer vision intuitive with lots of visualizations!** ðŸ–¼ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Part 1: Setup and Image Loading\n",
    "\n",
    "First, let's import all libraries and load a sample image to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"C:\\Users\\Zigron\\anaconda3\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:281\u001b[0m\n\u001b[0;32m    277\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    279\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 281\u001b[0m     _load_dll_libraries()\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:264\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    260\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    261\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    263\u001b[0m     )\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"C:\\Users\\Zigron\\anaconda3\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"âœ… Using PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample image\n",
    "# Using a simple cat image from the internet\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/481px-Cat03.jpg\"\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Resize to manageable size\n",
    "img = img.resize((224, 224))\n",
    "\n",
    "# Convert to numpy array\n",
    "img_array = np.array(img)\n",
    "\n",
    "print(f\"âœ… Image loaded successfully!\")\n",
    "print(f\"ðŸ“Š Image shape: {img_array.shape}\")\n",
    "print(f\"ðŸ“Š Data type: {img_array.dtype}\")\n",
    "print(f\"ðŸ“Š Pixel value range: [{img_array.min()}, {img_array.max()}]\")\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img_array)\n",
    "plt.title(\"Our Sample Image\", fontsize=16, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ This image is a 3D array: (Height=224, Width=224, Channels=3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¨ Part 2: Understanding Image Representation\n",
    "\n",
    "Let's visualize how computers see images - as grids of numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple 8x8 grayscale image to understand pixel values\n",
    "simple_img = np.array([\n",
    "    [0, 0, 0, 255, 255, 0, 0, 0],\n",
    "    [0, 0, 255, 255, 255, 255, 0, 0],\n",
    "    [0, 255, 255, 255, 255, 255, 255, 0],\n",
    "    [255, 255, 0, 255, 255, 0, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 0, 255, 255, 255, 255, 0, 255],\n",
    "    [0, 0, 0, 255, 255, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Image visualization\n",
    "axes[0].imshow(simple_img, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0].set_title(\"Grayscale Image (Visual)\", fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Number grid visualization\n",
    "axes[1].imshow(simple_img, cmap='gray', vmin=0, vmax=255)\n",
    "axes[1].set_title(\"Same Image (With Pixel Values)\", fontsize=14, fontweight='bold')\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        color = 'black' if simple_img[i, j] > 128 else 'white'\n",
    "        axes[1].text(j, i, str(simple_img[i, j]), \n",
    "                   ha='center', va='center', color=color, fontsize=9, fontweight='bold')\n",
    "axes[1].set_xticks(range(8))\n",
    "axes[1].set_yticks(range(8))\n",
    "axes[1].grid(True, color='red', linewidth=1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸŽ¯ Key Insights:\")\n",
    "print(\"â€¢ 0 = Black pixel\")\n",
    "print(\"â€¢ 255 = White pixel\")\n",
    "print(\"â€¢ Numbers in between = Shades of gray\")\n",
    "print(\"â€¢ Computers see this 8Ã—8 grid as 64 numbers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RGB channels separately\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(img_array)\n",
    "axes[0, 0].set_title(\"Original RGB Image\", fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Red channel\n",
    "red_channel = img_array[:, :, 0]\n",
    "axes[0, 1].imshow(red_channel, cmap='Reds')\n",
    "axes[0, 1].set_title(f\"Red Channel (Shape: {red_channel.shape})\", fontsize=14, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Green channel\n",
    "green_channel = img_array[:, :, 1]\n",
    "axes[1, 0].imshow(green_channel, cmap='Greens')\n",
    "axes[1, 0].set_title(f\"Green Channel (Shape: {green_channel.shape})\", fontsize=14, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Blue channel\n",
    "blue_channel = img_array[:, :, 2]\n",
    "axes[1, 1].imshow(blue_channel, cmap='Blues')\n",
    "axes[1, 1].set_title(f\"Blue Channel (Shape: {blue_channel.shape})\", fontsize=14, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸŽ¨ RGB Channel Breakdown:\")\n",
    "print(f\"â€¢ Original image: {img_array.shape} = (Height Ã— Width Ã— Channels)\")\n",
    "print(f\"â€¢ Each channel: {red_channel.shape} = (Height Ã— Width)\")\n",
    "print(f\"â€¢ Total numbers: {img_array.size:,} values!\")\n",
    "print(f\"\\nðŸ’¡ The computer processes {img_array.size:,} numbers for this one image!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Part 3: Manual Convolution Operation\n",
    "\n",
    "Let's perform convolution step-by-step to understand exactly how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_convolution(image, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Perform 2D convolution manually (step-by-step)\n",
    "    \n",
    "    Args:\n",
    "        image: Input 2D array\n",
    "        kernel: Filter/kernel 2D array\n",
    "        stride: Step size for sliding window\n",
    "        padding: Padding around the image\n",
    "    \n",
    "    Returns:\n",
    "        Output feature map\n",
    "    \"\"\"\n",
    "    # Add padding if needed\n",
    "    if padding > 0:\n",
    "        image = np.pad(image, padding, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Get dimensions\n",
    "    img_h, img_w = image.shape\n",
    "    kernel_h, kernel_w = kernel.shape\n",
    "    \n",
    "    # Calculate output dimensions\n",
    "    out_h = (img_h - kernel_h) // stride + 1\n",
    "    out_w = (img_w - kernel_w) // stride + 1\n",
    "    \n",
    "    # Initialize output\n",
    "    output = np.zeros((out_h, out_w))\n",
    "    \n",
    "    # Perform convolution\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            # Extract region\n",
    "            h_start = i * stride\n",
    "            w_start = j * stride\n",
    "            region = image[h_start:h_start+kernel_h, w_start:w_start+kernel_w]\n",
    "            \n",
    "            # Element-wise multiplication and sum\n",
    "            output[i, j] = np.sum(region * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Create a simple 5x5 input\n",
    "input_img = np.array([\n",
    "    [1, 2, 3, 0, 1],\n",
    "    [0, 1, 2, 3, 0],\n",
    "    [3, 0, 1, 2, 3],\n",
    "    [2, 3, 0, 1, 0],\n",
    "    [1, 0, 3, 2, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Create a 3x3 edge detection kernel (vertical)\n",
    "edge_kernel = np.array([\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Apply convolution\n",
    "output = manual_convolution(input_img, edge_kernel, stride=1, padding=0)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Input\n",
    "im1 = axes[0].imshow(input_img, cmap='viridis', vmin=0, vmax=3)\n",
    "axes[0].set_title(\"Input Image (5Ã—5)\", fontsize=14, fontweight='bold')\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[0].text(j, i, f'{input_img[i,j]:.0f}', \n",
    "                   ha='center', va='center', color='white', fontsize=10, fontweight='bold')\n",
    "axes[0].set_xticks(range(5))\n",
    "axes[0].set_yticks(range(5))\n",
    "axes[0].grid(True, color='white', linewidth=1)\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Kernel\n",
    "im2 = axes[1].imshow(edge_kernel, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[1].set_title(\"Vertical Edge Kernel (3Ã—3)\", fontsize=14, fontweight='bold')\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axes[1].text(j, i, f'{edge_kernel[i,j]:.0f}', \n",
    "                   ha='center', va='center', color='black', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xticks(range(3))\n",
    "axes[1].set_yticks(range(3))\n",
    "axes[1].grid(True, color='black', linewidth=1.5)\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Output\n",
    "im3 = axes[2].imshow(output, cmap='plasma')\n",
    "axes[2].set_title(f\"Output Feature Map ({output.shape[0]}Ã—{output.shape[1]})\", \n",
    "                 fontsize=14, fontweight='bold')\n",
    "for i in range(output.shape[0]):\n",
    "    for j in range(output.shape[1]):\n",
    "        axes[2].text(j, i, f'{output[i,j]:.0f}', \n",
    "                   ha='center', va='center', color='white', fontsize=10, fontweight='bold')\n",
    "axes[2].set_xticks(range(output.shape[1]))\n",
    "axes[2].set_yticks(range(output.shape[0]))\n",
    "axes[2].grid(True, color='white', linewidth=1)\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸŽ¯ Convolution Summary:\")\n",
    "print(f\"â€¢ Input size: {input_img.shape}\")\n",
    "print(f\"â€¢ Kernel size: {edge_kernel.shape}\")\n",
    "print(f\"â€¢ Output size: {output.shape}\")\n",
    "print(f\"â€¢ Stride: 1, Padding: 0\")\n",
    "print(f\"\\nðŸ’¡ Notice how the output is smaller: 5Ã—5 â†’ 3Ã—3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Challenge - Build Your Own CNN Layer\n",
    "\n",
    "**Your Task:** Create a convolutional layer that:\n",
    "1. Takes a grayscale image (1 channel)\n",
    "2. Outputs 8 feature maps\n",
    "3. Uses 5Ã—5 kernel\n",
    "4. Maintains input size (use appropriate padding)\n",
    "5. Visualize the output feature maps\n",
    "\n",
    "**Hints:**\n",
    "- For same padding with 5Ã—5 kernel: padding = 2\n",
    "- Convert to grayscale: gray_img = torch.from_numpy(np.mean(img_array, axis=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Summary & Key Takeaways\n",
    "\n",
    "### ðŸŽ“ What We Learned Today:\n",
    "\n",
    "**1. Image Representation:** Images are grids of numbers (0-255)\n",
    "\n",
    "**2. Convolution:** Sliding window that detects patterns\n",
    "\n",
    "**3. Kernels:** Small matrices that detect specific features\n",
    "\n",
    "**4. Padding:** Preserves spatial dimensions\n",
    "\n",
    "**5. Stride:** Controls output size\n",
    "\n",
    "**6. Feature Maps:** Shows where patterns detected\n",
    "\n",
    "**7. Receptive Field:** Grows with network depth\n",
    "\n",
    "### ðŸ’¡ Pro Tips:\n",
    "- Use 3Ã—3 kernels (most common)\n",
    "- Same padding preserves size\n",
    "- Stride=2 for downsampling\n",
    "- Visualize to understand!\n",
    "\n",
    "**Great job! You've mastered CNN fundamentals! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
