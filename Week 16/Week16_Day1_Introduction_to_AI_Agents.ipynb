{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Week 16 - Day 1: Introduction to AI Agents\n",
    "\n",
    "## Today's Goals:\n",
    "âœ… Understand what AI Agents are and why they matter\n",
    "\n",
    "âœ… Learn LangGraph fundamentals (Nodes, Edges, State)\n",
    "\n",
    "âœ… Create custom tools using the `@tool` decorator\n",
    "\n",
    "âœ… Build your first AI Agent with LangGraph\n",
    "\n",
    "âœ… Test agents with multiple tools\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Part 1: Setup - Install & Import All Libraries\n",
    "\n",
    "**IMPORTANT:** Run ALL cells in this part sequentially!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Installing packages... (this may take 1-2 minutes)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Zigron\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Zigron\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Zigron\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.0.3 requires langchain-core<0.3,>=0.1.52, but you have langchain-core 0.3.29 which is incompatible.\n",
      "langchain-openai 0.1.7 requires langchain-core<0.3,>=0.1.46, but you have langchain-core 0.3.29 which is incompatible.\n",
      "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.3.29 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Zigron\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Zigron\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Zigron\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All packages installed successfully!\n",
      "\n",
      "âš ï¸ NOTE: If you see version warnings above, they can be ignored.\n",
      "The packages will still work correctly for this notebook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Zigron\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Zigron\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (C:\\Users\\Zigron\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Install required packages\n",
    "print(\"ðŸ“¦ Installing packages... (this may take 1-2 minutes)\\n\")\n",
    "\n",
    "# IMPORTANT: Install with compatible versions to avoid conflicts\n",
    "!pip install -q langchain-core==0.3.29 langchain==0.3.14 langchain-community==0.3.14\n",
    "!pip install -q langgraph==0.2.61 langchain-groq==0.2.3\n",
    "!pip install -q python-dotenv\n",
    "\n",
    "print(\"\\nâœ… All packages installed successfully!\")\n",
    "print(\"\\nâš ï¸ NOTE: If you see version warnings above, they can be ignored.\")\n",
    "print(\"The packages will still work correctly for this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Import ALL libraries\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangGraph Core\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import create_react_agent, ToolNode\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# LangChain Core\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# LLM\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Type hints\n",
    "from typing import Annotated, TypedDict, Literal\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key configured!\n",
      "\n",
      "ðŸ’¡ Get a FREE Groq API key at: https://console.groq.com/\n",
      "ðŸš€ Ready to build AI Agents!\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Set up API Key for Groq (Free LLM API)\n",
    "# Get your free API key from: https://console.groq.com/\n",
    "\n",
    "# Option 1: Set directly (for learning - don't do this in production!)\n",
    "GROQ_API_KEY = \"your-groq-api-key-here\"  # Replace with your actual key\n",
    "\n",
    "# Option 2: Use environment variable (recommended)\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"your-key-here\"\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "\n",
    "print(\"âœ… API key configured!\")\n",
    "print(\"\\nðŸ’¡ Get a FREE Groq API key at: https://console.groq.com/\")\n",
    "print(\"ðŸš€ Ready to build AI Agents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ§  Part 2: Understanding AI Agents\n",
    "\n",
    "Before we code, let's understand what we're building!\n",
    "\n",
    "### ðŸŽ¯ What is an AI Agent?\n",
    "\n",
    "**An AI Agent is an LLM that can:**\n",
    "1. **Reason** about what to do next\n",
    "2. **Take actions** using tools\n",
    "3. **Observe** the results\n",
    "4. **Decide** if more actions are needed\n",
    "\n",
    "### ðŸ”„ The Agent Loop (ReAct Pattern):\n",
    "\n",
    "```\n",
    "User Query â†’ ðŸ¤” REASON â†’ ðŸ”§ ACT â†’ ðŸ‘€ OBSERVE â†’ ðŸ¤” REASON â†’ ... â†’ âœ… Final Answer\n",
    "```\n",
    "\n",
    "### ðŸ’¡ Key Difference: Chain vs Agent\n",
    "\n",
    "| Chain | Agent |\n",
    "|-------|-------|\n",
    "| Fixed steps | Dynamic decisions |\n",
    "| Always same path | Chooses which tool |\n",
    "| No loops | Can retry/iterate |\n",
    "| Predictable | Autonomous |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”· Part 3: LangGraph Fundamentals\n",
    "\n",
    "LangGraph helps us build agents using **graphs**. Let's understand the core concepts:\n",
    "\n",
    "### ðŸ“Š Graph Components:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    LangGraph                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                     â”‚\n",
    "â”‚   ðŸ“ NODES = Units of work (functions)              â”‚\n",
    "â”‚      â€¢ LLM calls                                    â”‚\n",
    "â”‚      â€¢ Tool execution                               â”‚\n",
    "â”‚      â€¢ Data processing                              â”‚\n",
    "â”‚                                                     â”‚\n",
    "â”‚   âž¡ï¸ EDGES = Connections between nodes              â”‚\n",
    "â”‚      â€¢ Normal: A â†’ B (always)                       â”‚\n",
    "â”‚      â€¢ Conditional: A â†’ B or C (based on logic)     â”‚\n",
    "â”‚                                                     â”‚\n",
    "â”‚   ðŸ“¦ STATE = Shared data across nodes               â”‚\n",
    "â”‚      â€¢ Messages history                             â”‚\n",
    "â”‚      â€¢ Variables                                    â”‚\n",
    "â”‚      â€¢ Context                                      â”‚\n",
    "â”‚                                                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ State Definition:\n",
      "   - messages: A list that stores all conversation messages\n",
      "   - add_messages: Automatically appends new messages (doesn't replace)\n",
      "\n",
      "ðŸ’¡ Think of State as a shared notebook that every node can read and write to!\n"
     ]
    }
   ],
   "source": [
    "# Let's understand State first - it's the \"memory\" of our agent\n",
    "\n",
    "# Define a simple State using TypedDict\n",
    "class SimpleState(TypedDict):\n",
    "    \"\"\"State that holds messages between nodes\"\"\"\n",
    "    messages: Annotated[list, add_messages]  # List of messages with auto-append\n",
    "\n",
    "print(\"ðŸ“¦ State Definition:\")\n",
    "print(\"   - messages: A list that stores all conversation messages\")\n",
    "print(\"   - add_messages: Automatically appends new messages (doesn't replace)\")\n",
    "print(\"\\nðŸ’¡ Think of State as a shared notebook that every node can read and write to!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Node functions defined!\n",
      "\n",
      "ðŸ“ Nodes are just Python functions that:\n",
      "   1. Take state as input\n",
      "   2. Do some work\n",
      "   3. Return updated state\n"
     ]
    }
   ],
   "source": [
    "# Let's build a simple graph to understand the flow\n",
    "\n",
    "# Step 1: Define a simple node function\n",
    "def greet_node(state: SimpleState):\n",
    "    \"\"\"A simple node that adds a greeting message\"\"\"\n",
    "    return {\"messages\": [AIMessage(content=\"Hello! I'm your AI assistant. How can I help?\")]}\n",
    "\n",
    "def process_node(state: SimpleState):\n",
    "    \"\"\"A node that processes the last message\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    response = f\"I received your message: '{last_message}'. Processing complete!\"\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "print(\"âœ… Node functions defined!\")\n",
    "print(\"\\nðŸ“ Nodes are just Python functions that:\")\n",
    "print(\"   1. Take state as input\")\n",
    "print(\"   2. Do some work\")\n",
    "print(\"   3. Return updated state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Graph built and compiled!\n",
      "\n",
      "ðŸ“Š Graph Structure:\n",
      "   START â†’ greeter â†’ processor â†’ END\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build the graph\n",
    "\n",
    "# Create a new graph with our state\n",
    "simple_graph = StateGraph(SimpleState)\n",
    "\n",
    "# Add nodes\n",
    "simple_graph.add_node(\"greeter\", greet_node)\n",
    "simple_graph.add_node(\"processor\", process_node)\n",
    "\n",
    "# Add edges (connections)\n",
    "simple_graph.add_edge(START, \"greeter\")      # Start â†’ Greeter\n",
    "simple_graph.add_edge(\"greeter\", \"processor\") # Greeter â†’ Processor\n",
    "simple_graph.add_edge(\"processor\", END)       # Processor â†’ End\n",
    "\n",
    "# Compile the graph\n",
    "simple_app = simple_graph.compile()\n",
    "\n",
    "print(\"âœ… Graph built and compiled!\")\n",
    "print(\"\\nðŸ“Š Graph Structure:\")\n",
    "print(\"   START â†’ greeter â†’ processor â†’ END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Graph Execution Results:\n",
      "\n",
      "==================================================\n",
      "\n",
      "Human: What can you do?\n",
      "\n",
      "AI: Hello! I'm your AI assistant. How can I help?\n",
      "\n",
      "AI: I received your message: 'Hello! I'm your AI assistant. How can I help?'. Processing complete!\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Run the graph!\n",
    "\n",
    "# Initial state with a user message\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"What can you do?\")]\n",
    "}\n",
    "\n",
    "# Run the graph\n",
    "result = simple_app.invoke(initial_state)\n",
    "\n",
    "print(\"ðŸš€ Graph Execution Results:\\n\")\n",
    "print(\"=\" * 50)\n",
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    role = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "    print(f\"\\n{role}: {msg.content}\")\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Key Insights:\n",
    "\n",
    "âœ… **StateGraph** creates a workflow from nodes and edges\n",
    "\n",
    "âœ… **Nodes** are functions that process and update state\n",
    "\n",
    "âœ… **Edges** define the flow between nodes\n",
    "\n",
    "âœ… **compile()** turns the graph into a runnable application\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Part 4: Creating Tools with @tool Decorator\n",
    "\n",
    "Tools give agents **superpowers** - the ability to take real actions!\n",
    "\n",
    "### What makes a good tool?\n",
    "1. **Clear name** - describes what it does\n",
    "2. **Docstring** - helps LLM understand when to use it\n",
    "3. **Type hints** - define input/output types\n",
    "4. **Single purpose** - does one thing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Calculator tools created!\n",
      "\n",
      "ðŸ”§ Available tools:\n",
      "   1. add: Add two numbers together.\n",
      "\n",
      "    Args:\n",
      "        a: First number\n",
      "        b: Second number\n",
      "   2. multiply: Multiply two numbers together.\n",
      "\n",
      "    Args:\n",
      "        a: First number\n",
      "        b: Second number\n",
      "   3. subtract: Subtract the second number from the first.\n",
      "\n",
      "    Args:\n",
      "        a: First number\n",
      "        b: Second number to subtract\n"
     ]
    }
   ],
   "source": [
    "# Let's create some simple tools!\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers together.\n",
    "    \n",
    "    Args:\n",
    "        a: First number\n",
    "        b: Second number\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers together.\n",
    "    \n",
    "    Args:\n",
    "        a: First number\n",
    "        b: Second number\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract the second number from the first.\n",
    "    \n",
    "    Args:\n",
    "        a: First number\n",
    "        b: Second number to subtract\n",
    "    \"\"\"\n",
    "    return a - b\n",
    "\n",
    "print(\"âœ… Calculator tools created!\")\n",
    "print(\"\\nðŸ”§ Available tools:\")\n",
    "print(f\"   1. {add.name}: {add.description}\")\n",
    "print(f\"   2. {multiply.name}: {multiply.description}\")\n",
    "print(f\"   3. {subtract.name}: {subtract.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Examining the 'add' tool:\n",
      "\n",
      "ðŸ“› Name: add\n",
      "ðŸ“ Description: Add two numbers together.\n",
      "\n",
      "    Args:\n",
      "        a: First number\n",
      "        b: Second number\n",
      "ðŸ“Š Arguments: {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n",
      "\n",
      "ðŸ’¡ The LLM uses this information to decide WHEN and HOW to call the tool!\n"
     ]
    }
   ],
   "source": [
    "# Let's examine what the @tool decorator creates\n",
    "\n",
    "print(\"ðŸ” Examining the 'add' tool:\\n\")\n",
    "print(f\"ðŸ“› Name: {add.name}\")\n",
    "print(f\"ðŸ“ Description: {add.description}\")\n",
    "print(f\"ðŸ“Š Arguments: {add.args}\")\n",
    "print(f\"\\nðŸ’¡ The LLM uses this information to decide WHEN and HOW to call the tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing tools manually:\n",
      "\n",
      "add(5, 3) = 8\n",
      "multiply(4, 7) = 28\n",
      "subtract(10, 4) = 6\n",
      "\n",
      "âœ… All tools working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test the tools manually\n",
    "\n",
    "print(\"ðŸ§ª Testing tools manually:\\n\")\n",
    "\n",
    "# Tools can be invoked directly\n",
    "result1 = add.invoke({\"a\": 5, \"b\": 3})\n",
    "print(f\"add(5, 3) = {result1}\")\n",
    "\n",
    "result2 = multiply.invoke({\"a\": 4, \"b\": 7})\n",
    "print(f\"multiply(4, 7) = {result2}\")\n",
    "\n",
    "result3 = subtract.invoke({\"a\": 10, \"b\": 4})\n",
    "print(f\"subtract(10, 4) = {result3}\")\n",
    "\n",
    "print(\"\\nâœ… All tools working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… String tools created!\n",
      "\n",
      "ðŸ”§ New tools available:\n",
      "   â€¢ get_word_length: Get the length of a word (number of characters).\n",
      "\n",
      "    Args:\n",
      "        word: The word to measure\n",
      "   â€¢ reverse_string: Reverse a string (spell it backwards).\n",
      "\n",
      "    Args:\n",
      "        text: The text to reverse\n",
      "   â€¢ count_vowels: Count the number of vowels (a, e, i, o, u) in a text.\n",
      "\n",
      "    Args:\n",
      "        text: The text to analyze\n"
     ]
    }
   ],
   "source": [
    "# Let's create more interesting tools!\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Get the length of a word (number of characters).\n",
    "    \n",
    "    Args:\n",
    "        word: The word to measure\n",
    "    \"\"\"\n",
    "    return len(word)\n",
    "\n",
    "@tool\n",
    "def reverse_string(text: str) -> str:\n",
    "    \"\"\"Reverse a string (spell it backwards).\n",
    "    \n",
    "    Args:\n",
    "        text: The text to reverse\n",
    "    \"\"\"\n",
    "    return text[::-1]\n",
    "\n",
    "@tool\n",
    "def count_vowels(text: str) -> int:\n",
    "    \"\"\"Count the number of vowels (a, e, i, o, u) in a text.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to analyze\n",
    "    \"\"\"\n",
    "    vowels = \"aeiouAEIOU\"\n",
    "    return sum(1 for char in text if char in vowels)\n",
    "\n",
    "print(\"âœ… String tools created!\")\n",
    "print(\"\\nðŸ”§ New tools available:\")\n",
    "print(f\"   â€¢ get_word_length: {get_word_length.description}\")\n",
    "print(f\"   â€¢ reverse_string: {reverse_string.description}\")\n",
    "print(f\"   â€¢ count_vowels: {count_vowels.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Key Insights:\n",
    "\n",
    "âœ… **@tool decorator** converts functions into LangChain tools\n",
    "\n",
    "âœ… **Docstrings are CRITICAL** - they help the LLM understand when to use the tool\n",
    "\n",
    "âœ… **Type hints are REQUIRED** - they define the input schema\n",
    "\n",
    "âœ… **Tools can be tested** directly with `.invoke()`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– Part 5: Building Your First AI Agent\n",
    "\n",
    "Now let's combine everything to build a real AI Agent!\n",
    "\n",
    "We'll use LangGraph's `create_react_agent` - a prebuilt agent that implements the ReAct pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM initialized!\n",
      "ðŸ“Š Model: Llama 3.1 8B (via Groq)\n",
      "âš¡ Groq provides ultra-fast inference!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize the LLM\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",  # Fast and capable!\n",
    "    temperature=0,  # Deterministic outputs\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(\"âœ… LLM initialized!\")\n",
    "print(\"ðŸ“Š Model: Llama 3.1 8B (via Groq)\")\n",
    "print(\"âš¡ Groq provides ultra-fast inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Math Agent created!\n",
      "\n",
      "ðŸ¤– Agent capabilities:\n",
      "   â€¢ Can add numbers\n",
      "   â€¢ Can multiply numbers\n",
      "   â€¢ Can subtract numbers\n",
      "   â€¢ Decides which tool to use based on the question!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create the agent with tools\n",
    "\n",
    "# Collect our math tools\n",
    "math_tools = [add, multiply, subtract]\n",
    "\n",
    "# Create the agent using create_react_agent (easiest way!)\n",
    "math_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=math_tools\n",
    ")\n",
    "\n",
    "print(\"âœ… Math Agent created!\")\n",
    "print(\"\\nðŸ¤– Agent capabilities:\")\n",
    "print(\"   â€¢ Can add numbers\")\n",
    "print(\"   â€¢ Can multiply numbers\")\n",
    "print(\"   â€¢ Can subtract numbers\")\n",
    "print(\"   â€¢ Decides which tool to use based on the question!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Test the agent!\n",
    "\n",
    "def ask_agent(agent, question):\n",
    "    \"\"\"Helper function to ask questions to an agent\"\"\"\n",
    "    print(f\"\\nâ“ Question: {question}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Run the agent\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=question)]\n",
    "    })\n",
    "    \n",
    "    # Display all messages\n",
    "    print(\"\\nðŸ“ Agent's Thought Process:\")\n",
    "    for msg in result[\"messages\"]:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            print(f\"\\nðŸ‘¤ Human: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            if msg.tool_calls:\n",
    "                for tc in msg.tool_calls:\n",
    "                    print(f\"\\nðŸ”§ Tool Call: {tc['name']}({tc['args']})\")\n",
    "            else:\n",
    "                print(f\"\\nðŸ¤– AI: {msg.content}\")\n",
    "        else:\n",
    "            # Tool message\n",
    "            print(f\"\\nðŸ“¤ Tool Result: {msg.content}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â“ Question: What is 15 plus 27?\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test 1: Simple addition\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result1 = \u001b[43mask_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmath_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is 15 plus 27?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mask_agent\u001b[39m\u001b[34m(agent, question)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Run the agent\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Display all messages\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“ Agent\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms Thought Process:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1940\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   1938\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1939\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1948\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1949\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1950\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1660\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   1657\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   1658\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[32m   1659\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m1660\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1661\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1663\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   1667\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langgraph\\pregel\\runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    404\u001b[39m config = patch_config(\n\u001b[32m    405\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    406\u001b[39m )\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    410\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langgraph\\utils\\runnable.py:176\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m     context = copy_context()\n\u001b[32m    175\u001b[39m     context.run(_set_config_context, child_config)\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    178\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:560\u001b[39m, in \u001b[36mcreate_react_agent.<locals>.call_model\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(state: AgentState, config: RunnableConfig) -> AgentState:\n\u001b[32m    559\u001b[39m     _validate_chat_history(state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     response = \u001b[43mmodel_runnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     has_tool_calls = \u001b[38;5;28misinstance\u001b[39m(response, AIMessage) \u001b[38;5;129;01mand\u001b[39;00m response.tool_calls\n\u001b[32m    562\u001b[39m     all_tools_return_direct = (\n\u001b[32m    563\u001b[39m         \u001b[38;5;28mall\u001b[39m(call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m should_return_direct \u001b[38;5;28;01mfor\u001b[39;00m call \u001b[38;5;129;01min\u001b[39;00m response.tool_calls)\n\u001b[32m    564\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, AIMessage)\n\u001b[32m    565\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    566\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3246\u001b[39m, in \u001b[36minvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3232\u001b[39m # start the root runs, one per input\n\u001b[32m   3233\u001b[39m run_managers: list[AsyncCallbackManagerForChainRun] = await asyncio.gather(\n\u001b[32m   3234\u001b[39m     *(\n\u001b[32m   3235\u001b[39m         cm.on_chain_start(\n\u001b[32m   (...)\u001b[39m\u001b[32m   3242\u001b[39m     )\n\u001b[32m   3243\u001b[39m )\n\u001b[32m   3245\u001b[39m # invoke .batch() on each step\n\u001b[32m-> \u001b[39m\u001b[32m3246\u001b[39m # this uses batching optimizations in Runnable subclasses, like LLM\n\u001b[32m   3247\u001b[39m try:\n\u001b[32m   3248\u001b[39m     if return_exceptions:\n\u001b[32m   3249\u001b[39m         # Track which inputs (by index) failed so far\n\u001b[32m   3250\u001b[39m         # If an input has failed it will be present in this map,\n\u001b[32m   3251\u001b[39m         # and the value will be the exception that was raised.\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5711\u001b[39m, in \u001b[36minvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5681\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Bind lifecycle listeners to a Runnable, returning a new Runnable.\u001b[39;00m\n\u001b[32m   5682\u001b[39m \n\u001b[32m   5683\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5694\u001b[39m \u001b[33;03m    added to the run.\u001b[39;00m\n\u001b[32m   5695\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5696\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mroot_listeners\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RootListenersTracer\n\u001b[32m   5698\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m(\n\u001b[32m   5699\u001b[39m     bound=\u001b[38;5;28mself\u001b[39m.bound,\n\u001b[32m   5700\u001b[39m     kwargs=\u001b[38;5;28mself\u001b[39m.kwargs,\n\u001b[32m   5701\u001b[39m     config=\u001b[38;5;28mself\u001b[39m.config,\n\u001b[32m   5702\u001b[39m     config_factories=[\n\u001b[32m   5703\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m config: {\n\u001b[32m   5704\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   5705\u001b[39m                 RootListenersTracer(\n\u001b[32m   5706\u001b[39m                     config=config,\n\u001b[32m   5707\u001b[39m                     on_start=on_start,\n\u001b[32m   5708\u001b[39m                     on_end=on_end,\n\u001b[32m   5709\u001b[39m                     on_error=on_error,\n\u001b[32m   5710\u001b[39m                 )\n\u001b[32m-> \u001b[39m\u001b[32m5711\u001b[39m             ],\n\u001b[32m   5712\u001b[39m         }\n\u001b[32m   5713\u001b[39m     ],\n\u001b[32m   5714\u001b[39m     custom_input_type=\u001b[38;5;28mself\u001b[39m.custom_input_type,\n\u001b[32m   5715\u001b[39m     custom_output_type=\u001b[38;5;28mself\u001b[39m.custom_output_type,\n\u001b[32m   5716\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36minvoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1025\u001b[39m, in \u001b[36mgenerate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[39m, in \u001b[36mgenerate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    840\u001b[39m chunk.message.response_metadata = _gen_info_and_msg_metadata(chunk)\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager:\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunk.message.id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    843\u001b[39m         chunk.message.id = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrun-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_manager.run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    844\u001b[39m     run_manager.on_llm_new_token(\n\u001b[32m    845\u001b[39m         cast(\u001b[38;5;28mstr\u001b[39m, chunk.message.content), chunk=chunk\n\u001b[32m    846\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[39m, in \u001b[36m_generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1083\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mCannot use predict when output is not a string.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1084\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1086\u001b[39m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m0.1.7\u001b[39m\u001b[33m\"\u001b[39m, alternative=\u001b[33m\"\u001b[39m\u001b[33mainvoke\u001b[39m\u001b[33m\"\u001b[39m, removal=\u001b[33m\"\u001b[39m\u001b[33m1.0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapredict_messages\u001b[39m(\n\u001b[32m   1088\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1089\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   1090\u001b[39m     *,\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     stop: Optional[Sequence[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1092\u001b[39m     **kwargs: Any,\n\u001b[32m   1093\u001b[39m ) -> BaseMessage:\n\u001b[32m   1094\u001b[39m     _stop = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(stop)\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_async(messages, stop=_stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\langchain_groq\\chat_models.py:480\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    476\u001b[39m params = {\n\u001b[32m    477\u001b[39m     **params,\n\u001b[32m    478\u001b[39m     **kwargs,\n\u001b[32m    479\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:464\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    245\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    246\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    303\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    304\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    305\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    307\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    462\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcitation_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompound_custom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisable_tool_validation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tool_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\groq\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ai_bootcamp\\Lib\\site-packages\\groq\\_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}",
      "During task with name 'agent' and id 'e70333f5-6144-5122-45b7-e292ea0784d0'"
     ]
    }
   ],
   "source": [
    "# Test 1: Simple addition\n",
    "result1 = ask_agent(math_agent, \"What is 15 plus 27?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Multiplication\n",
    "result2 = ask_agent(math_agent, \"Can you multiply 8 and 9?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Multi-step calculation\n",
    "result3 = ask_agent(math_agent, \"What is 10 plus 5, then multiply that by 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Agent decides which tool to use\n",
    "result4 = ask_agent(math_agent, \"I have 100 apples and give away 37. How many do I have left?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Key Observations:\n",
    "\n",
    "âœ… **The agent REASONS** about which tool to use\n",
    "\n",
    "âœ… **It ACTS** by calling the appropriate tool\n",
    "\n",
    "âœ… **It OBSERVES** the result\n",
    "\n",
    "âœ… **It DECIDES** if more actions are needed or provides the final answer\n",
    "\n",
    "This is the **ReAct pattern** in action!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Part 6: Agent with Multiple Tool Types\n",
    "\n",
    "Let's create a more versatile agent with different types of tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with both math and string tools\n",
    "\n",
    "all_tools = [\n",
    "    add, \n",
    "    multiply, \n",
    "    subtract,\n",
    "    get_word_length,\n",
    "    reverse_string,\n",
    "    count_vowels\n",
    "]\n",
    "\n",
    "# Create a versatile agent\n",
    "versatile_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=all_tools\n",
    ")\n",
    "\n",
    "print(\"âœ… Versatile Agent created!\")\n",
    "print(\"\\nðŸ¤– This agent can:\")\n",
    "print(\"   ðŸ“Š Math: add, multiply, subtract\")\n",
    "print(\"   ðŸ“ Text: word length, reverse, count vowels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with string operations\n",
    "result5 = ask_agent(versatile_agent, \"How many characters are in the word 'LangGraph'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test string reversal\n",
    "result6 = ask_agent(versatile_agent, \"What is 'artificial' spelled backwards?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test vowel counting\n",
    "result7 = ask_agent(versatile_agent, \"How many vowels are in the word 'intelligence'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test mixed: Agent chooses the right tool!\n",
    "result8 = ask_agent(versatile_agent, \"Add 5 and 3, then tell me how many vowels are in the word 'eight'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”¨ Part 7: Building an Agent from Scratch (Custom Graph)\n",
    "\n",
    "Let's understand how agents work internally by building one step-by-step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the State for our agent\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State for our custom agent\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "print(\"âœ… Agent State defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create the LLM with tools bound to it\n",
    "\n",
    "# Our tools for this agent\n",
    "tools = [add, multiply, subtract]\n",
    "\n",
    "# Bind tools to the LLM - this lets the LLM know about available tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"âœ… LLM bound with tools!\")\n",
    "print(\"\\nðŸ’¡ bind_tools() tells the LLM:\")\n",
    "print(\"   â€¢ What tools are available\")\n",
    "print(\"   â€¢ How to call them (arguments)\")\n",
    "print(\"   â€¢ When to use them (based on descriptions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the \"agent\" node - calls the LLM\n",
    "\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"The agent node: calls the LLM to decide what to do\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"âœ… Agent node defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create the tool node using LangGraph's prebuilt ToolNode\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "print(\"âœ… Tool node created!\")\n",
    "print(\"\\nðŸ’¡ ToolNode automatically:\")\n",
    "print(\"   â€¢ Reads tool calls from the last message\")\n",
    "print(\"   â€¢ Executes the appropriate tool\")\n",
    "print(\"   â€¢ Returns the result as a message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the conditional edge - should we continue or stop?\n",
    "\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n",
    "    \"\"\"Decide whether to use tools or end the conversation\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the LLM wants to call a tool, go to tools node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # Otherwise, we're done\n",
    "    return \"end\"\n",
    "\n",
    "print(\"âœ… Conditional edge function defined!\")\n",
    "print(\"\\nðŸ’¡ This function decides:\")\n",
    "print(\"   â€¢ If LLM made tool_calls â†’ go to 'tools' node\")\n",
    "print(\"   â€¢ Otherwise â†’ go to 'end' (finish)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Build the graph!\n",
    "\n",
    "# Create the graph\n",
    "custom_graph = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "custom_graph.add_node(\"agent\", agent_node)\n",
    "custom_graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Add edges\n",
    "custom_graph.add_edge(START, \"agent\")  # Start â†’ Agent\n",
    "\n",
    "# Add conditional edge from agent\n",
    "custom_graph.add_conditional_edges(\n",
    "    \"agent\",  # From node\n",
    "    should_continue,  # Function that decides\n",
    "    {\n",
    "        \"tools\": \"tools\",  # If should_continue returns \"tools\"\n",
    "        \"end\": END  # If should_continue returns \"end\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After tools, go back to agent (loop!)\n",
    "custom_graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "custom_agent = custom_graph.compile()\n",
    "\n",
    "print(\"âœ… Custom Agent Graph compiled!\")\n",
    "print(\"\\nðŸ“Š Graph Structure:\")\n",
    "print(\"   START â†’ agent âŸ· tools\")\n",
    "print(\"              â†“\")\n",
    "print(\"             END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our custom agent!\n",
    "result9 = ask_agent(custom_agent, \"What is 25 multiplied by 4?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multi-step reasoning\n",
    "result10 = ask_agent(custom_agent, \"Calculate 50 minus 15, then add 10 to that result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Understanding the Agent Loop:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                                                     â”‚\n",
    "â”‚   START                                             â”‚\n",
    "â”‚     â”‚                                               â”‚\n",
    "â”‚     â–¼                                               â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”    tool_calls?    â”Œâ”€â”€â”€â”€â”€â”€â”€â”              â”‚\n",
    "â”‚  â”‚AGENT â”‚ â”€â”€â”€â”€â”€â”€â”€Yesâ”€â”€â”€â”€â”€â”€â–º â”‚ TOOLS â”‚              â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚\n",
    "â”‚     â”‚                           â”‚                   â”‚\n",
    "â”‚     â”‚ No                        â”‚                   â”‚\n",
    "â”‚     â”‚                           â”‚                   â”‚\n",
    "â”‚     â–¼                           â”‚                   â”‚\n",
    "â”‚    END â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
    "â”‚         (loop back to agent)                        â”‚\n",
    "â”‚                                                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Part 8: Mini Challenge\n",
    "\n",
    "### ðŸ† Challenge: Create Your Own Agent!\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create 2-3 new tools (be creative!)\n",
    "2. Build an agent with these tools\n",
    "3. Test your agent with various questions\n",
    "\n",
    "**Ideas for tools:**\n",
    "- Temperature converter (Celsius â†” Fahrenheit)\n",
    "- BMI calculator\n",
    "- Simple tip calculator\n",
    "- Word counter\n",
    "- Text to uppercase/lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# Example structure:\n",
    "\n",
    "# Step 1: Create your tools\n",
    "# @tool\n",
    "# def my_tool(param: type) -> return_type:\n",
    "#     \"\"\"Description of what this tool does\"\"\"\n",
    "#     return result\n",
    "\n",
    "# Step 2: Create your agent\n",
    "# my_tools = [tool1, tool2, tool3]\n",
    "# my_agent = create_react_agent(model=llm, tools=my_tools)\n",
    "\n",
    "# Step 3: Test it!\n",
    "# ask_agent(my_agent, \"Your question here\")\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Example (Temperature Converter)\n",
    "\n",
    "@tool\n",
    "def celsius_to_fahrenheit(celsius: float) -> float:\n",
    "    \"\"\"Convert temperature from Celsius to Fahrenheit.\n",
    "    \n",
    "    Args:\n",
    "        celsius: Temperature in Celsius\n",
    "    \"\"\"\n",
    "    return (celsius * 9/5) + 32\n",
    "\n",
    "@tool\n",
    "def fahrenheit_to_celsius(fahrenheit: float) -> float:\n",
    "    \"\"\"Convert temperature from Fahrenheit to Celsius.\n",
    "    \n",
    "        Args:\n",
    "        fahrenheit: Temperature in Fahrenheit\n",
    "    \"\"\"\n",
    "    return (fahrenheit - 32) * 5/9\n",
    "\n",
    "@tool\n",
    "def calculate_tip(bill_amount: float, tip_percentage: float) -> float:\n",
    "    \"\"\"Calculate the tip amount for a bill.\n",
    "    \n",
    "    Args:\n",
    "        bill_amount: The total bill amount\n",
    "        tip_percentage: The tip percentage (e.g., 15 for 15%)\n",
    "    \"\"\"\n",
    "    return bill_amount * (tip_percentage / 100)\n",
    "\n",
    "# Create the agent\n",
    "utility_tools = [celsius_to_fahrenheit, fahrenheit_to_celsius, calculate_tip]\n",
    "utility_agent = create_react_agent(model=llm, tools=utility_tools)\n",
    "\n",
    "print(\"âœ… Utility Agent created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the utility agent\n",
    "ask_agent(utility_agent, \"What is 100 degrees Fahrenheit in Celsius?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test tip calculation\n",
    "ask_agent(utility_agent, \"My bill is $85. How much should I tip at 18%?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“š Summary - What We Learned Today\n",
    "\n",
    "### 1. AI Agents Fundamentals ðŸ¤–\n",
    "- Agents can **reason**, **act**, and **observe**\n",
    "- They follow the **ReAct pattern** (Reasoning + Acting)\n",
    "- Unlike chains, agents make **dynamic decisions**\n",
    "\n",
    "### 2. LangGraph Core Concepts ðŸ”·\n",
    "- **State**: Shared data between nodes (like a notebook)\n",
    "- **Nodes**: Units of work (Python functions)\n",
    "- **Edges**: Connections that define flow\n",
    "- **Conditional Edges**: Dynamic routing based on logic\n",
    "\n",
    "### 3. Creating Tools ðŸ› ï¸\n",
    "- Use `@tool` decorator to create tools\n",
    "- **Docstrings are essential** - they guide the LLM\n",
    "- **Type hints are required** - they define the schema\n",
    "- Tools can be tested with `.invoke()`\n",
    "\n",
    "### 4. Building Agents ðŸš€\n",
    "- `create_react_agent()` is the easiest way to start\n",
    "- Custom graphs give more control\n",
    "- The agent loop: Agent â†’ Tools â†’ Agent â†’ ... â†’ End\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Key Takeaways\n",
    "\n",
    "âœ… **Agents = LLM + Tools + Decision Loop**\n",
    "\n",
    "âœ… **LangGraph makes it easy** to build agent workflows\n",
    "\n",
    "âœ… **Good tools have clear names and descriptions**\n",
    "\n",
    "âœ… **Start with `create_react_agent`**, then customize as needed\n",
    "\n",
    "âœ… **The agent decides** which tool to use and when\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¡ Pro Tips\n",
    "\n",
    "1. **Write clear docstrings** - The LLM reads them to understand tools\n",
    "2. **Keep tools focused** - One tool, one job\n",
    "3. **Test tools independently** before using in agents\n",
    "4. **Use `create_react_agent`** for quick prototyping\n",
    "5. **Build custom graphs** when you need more control\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Next Steps - Tomorrow!\n",
    "\n",
    "**Day 2: LangGraph Workflows**\n",
    "- Conditional and parallel edges\n",
    "- Multi-agent workflow creation\n",
    "- Inter-agent communication\n",
    "- Tool orchestration\n",
    "\n",
    "**Get ready to build complex agent systems! ðŸš€**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've built your first AI Agents!\n",
    "\n",
    "You now know how to:\n",
    "- âœ… Understand what AI Agents are\n",
    "- âœ… Work with LangGraph (State, Nodes, Edges)\n",
    "- âœ… Create custom tools with `@tool`\n",
    "- âœ… Build agents with `create_react_agent`\n",
    "- âœ… Build custom agent graphs from scratch\n",
    "\n",
    "**Keep practicing and see you tomorrow! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
