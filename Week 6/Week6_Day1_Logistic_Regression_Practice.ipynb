{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì AI Bootcamp - Week 6 Day 1\n",
    "## Logistic Regression: Binary Classification\n",
    "\n",
    "### Today's Learning Goals:\n",
    "- ‚úÖ Understand classification vs regression\n",
    "- ‚úÖ Implement logistic regression with scikit-learn\n",
    "- ‚úÖ Work with probabilities and thresholds\n",
    "- ‚úÖ Build and interpret confusion matrices\n",
    "- ‚úÖ Calculate accuracy, precision, recall, F1-score\n",
    "- ‚úÖ Apply to Titanic survival prediction\n",
    "\n",
    "---\n",
    "\n",
    "**Let's start classifying! üöÄ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score, \n",
    "    recall_score, f1_score, classification_report, roc_curve, auc\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "print('‚úÖ Libraries loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the Sigmoid Function\n",
    "\n",
    "The sigmoid function œÉ(z) = 1 / (1 + e^(-z)) converts any number into a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = np.linspace(-10, 10, 200)\n",
    "sigma = sigmoid(z)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(z, sigma, 'b-', linewidth=2, label='Sigmoid œÉ(z)')\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Threshold = 0.5')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('z (input)', fontsize=12)\n",
    "plt.ylabel('œÉ(z) (probability)', fontsize=12)\n",
    "plt.title('Sigmoid Function: The Heart of Logistic Regression', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.show()\n",
    "\n",
    "print('Key observations:')\n",
    "print(f'œÉ(-5) = {sigmoid(-5):.4f} (very unlikely)')\n",
    "print(f'œÉ(0)  = {sigmoid(0):.4f} (50-50 chance)')\n",
    "print(f'œÉ(5)  = {sigmoid(5):.4f} (very likely)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Simple Binary Classification Example\n",
    "\n",
    "Let's create a simple dataset and train our first classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simple binary classification data\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=200, n_features=2, n_informative=2,\n",
    "    n_redundant=0, n_clusters_per_class=1, random_state=42\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], c='red', label='Class 0', alpha=0.6, s=50)\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], c='blue', label='Class 1', alpha=0.6, s=50)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Binary Classification Dataset', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f'Training samples: {len(X_train)}')\n",
    "print(f'Test samples: {len(X_test)}')\n",
    "print(f'Class distribution: {np.bincount(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
    "\n",
    "print('‚úÖ Model trained!')\n",
    "print(f'\\nCoefficients: {model.coef_[0]}')\n",
    "print(f'Intercept: {model.intercept_[0]:.4f}')\n",
    "print(f'\\nSample predictions (first 5):')\n",
    "for i in range(5):\n",
    "    print(f'  True: {y_test[i]}, Predicted: {y_pred[i]}, Probability: {y_pred_proba[i]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Confusion Matrix\n",
    "\n",
    "The confusion matrix shows all four possible outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Extract values\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print('Confusion Matrix Breakdown:')\n",
    "print(f'  True Negatives (TN):  {tn} - Correctly predicted class 0')\n",
    "print(f'  False Positives (FP): {fp} - Incorrectly predicted class 1')\n",
    "print(f'  False Negatives (FN): {fn} - Incorrectly predicted class 0')\n",
    "print(f'  True Positives (TP):  {tp} - Correctly predicted class 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluation Metrics\n",
    "\n",
    "Calculate all the key metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics manually\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print('Manual Calculation:')\n",
    "print(f'  Accuracy:  {accuracy:.3f}')\n",
    "print(f'  Precision: {precision:.3f}')\n",
    "print(f'  Recall:    {recall:.3f}')\n",
    "print(f'  F1-Score:  {f1:.3f}')\n",
    "\n",
    "# Using scikit-learn functions\n",
    "print('\\nUsing scikit-learn:')\n",
    "print(f'  Accuracy:  {accuracy_score(y_test, y_pred):.3f}')\n",
    "print(f'  Precision: {precision_score(y_test, y_pred):.3f}')\n",
    "print(f'  Recall:    {recall_score(y_test, y_pred):.3f}')\n",
    "print(f'  F1-Score:  {f1_score(y_test, y_pred):.3f}')\n",
    "\n",
    "# Full classification report\n",
    "print('\\nFull Classification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Experimenting with Thresholds\n",
    "\n",
    "The default threshold is 0.5, but we can adjust it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different thresholds\n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_custom = (y_pred_proba >= threshold).astype(int)\n",
    "    acc = accuracy_score(y_test, y_pred_custom)\n",
    "    prec = precision_score(y_test, y_pred_custom)\n",
    "    rec = recall_score(y_test, y_pred_custom)\n",
    "    f1 = f1_score(y_test, y_pred_custom)\n",
    "    \n",
    "    results.append({\n",
    "        'Threshold': threshold,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print('Effect of Different Thresholds:')\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, threshold in enumerate(thresholds):\n",
    "    y_pred_custom = (y_pred_proba >= threshold).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred_custom)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Threshold = {threshold}')\n",
    "    axes[idx].set_ylabel('True')\n",
    "    axes[idx].set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nüìä Observation: Lower threshold ‚Üí More positives, higher recall')\n",
    "print('üìä Observation: Higher threshold ‚Üí Fewer positives, higher precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: ROC Curve and AUC\n",
    "\n",
    "The ROC curve shows performance across all thresholds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Recall)', fontsize=12)\n",
    "plt.title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f'AUC Score: {roc_auc:.3f}')\n",
    "print('\\nInterpretation:')\n",
    "print('  AUC = 1.0: Perfect classifier')\n",
    "print('  AUC = 0.5: Random classifier')\n",
    "print('  AUC > 0.7: Good classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: TITANIC DATASET - Real World Application\n",
    "\n",
    "Let's predict Titanic survival using logistic regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic data\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'\\nFirst few rows:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select features\n",
    "df_clean = df[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].copy()\n",
    "\n",
    "# Handle missing values\n",
    "df_clean['Age'].fillna(df_clean['Age'].median(), inplace=True)\n",
    "df_clean['Fare'].fillna(df_clean['Fare'].median(), inplace=True)\n",
    "\n",
    "# Encode Sex\n",
    "df_clean['Sex'] = LabelEncoder().fit_transform(df_clean['Sex'])\n",
    "\n",
    "print('Clean dataset:')\n",
    "print(df_clean.info())\n",
    "print(f'\\nSurvival rate: {df_clean[\"Survived\"].mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X_titanic = df_clean.drop('Survived', axis=1)\n",
    "y_titanic = df_clean['Survived']\n",
    "\n",
    "# Split data\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "    X_titanic, y_titanic, test_size=0.2, random_state=42, stratify=y_titanic\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_t)\n",
    "X_test_scaled = scaler.transform(X_test_t)\n",
    "\n",
    "print(f'Training samples: {len(X_train_t)}')\n",
    "print(f'Test samples: {len(X_test_t)}')\n",
    "print(f'\\nClass distribution:')\n",
    "print(y_titanic.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on Titanic data\n",
    "model_titanic = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_titanic.fit(X_train_scaled, y_train_t)\n",
    "\n",
    "# Predictions\n",
    "y_pred_t = model_titanic.predict(X_test_scaled)\n",
    "y_pred_proba_t = model_titanic.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print('‚úÖ Titanic model trained!')\n",
    "print(f'\\nTest Accuracy: {accuracy_score(y_test_t, y_pred_t):.3f}')\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_titanic.columns,\n",
    "    'Coefficient': model_titanic.coef_[0]\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print('\\nFeature Importance (by coefficient magnitude):')\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for Titanic\n",
    "cm_titanic = confusion_matrix(y_test_t, y_pred_t)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_titanic, annot=True, fmt='d', cmap='RdYlGn',\n",
    "            xticklabels=['Did Not Survive', 'Survived'],\n",
    "            yticklabels=['Did Not Survive', 'Survived'])\n",
    "plt.title('Titanic Survival Prediction - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Metrics\n",
    "print('\\nTitanic Model Performance:')\n",
    "print(classification_report(y_test_t, y_pred_t, \n",
    "                          target_names=['Did Not Survive', 'Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample predictions\n",
    "sample_passengers = X_test_t.head(10).copy()\n",
    "sample_actual = y_test_t.head(10).values\n",
    "sample_pred = y_pred_t[:10]\n",
    "sample_proba = y_pred_proba_t[:10]\n",
    "\n",
    "print('Sample Predictions:')\n",
    "print('=' * 80)\n",
    "for i in range(10):\n",
    "    actual = 'Survived' if sample_actual[i] == 1 else 'Did Not Survive'\n",
    "    predicted = 'Survived' if sample_pred[i] == 1 else 'Did Not Survive'\n",
    "    prob = sample_proba[i]\n",
    "    correct = '‚úÖ' if sample_actual[i] == sample_pred[i] else '‚ùå'\n",
    "    \n",
    "    print(f'{correct} Actual: {actual:20} | Predicted: {predicted:20} | Prob: {prob:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Your Challenge\n",
    "\n",
    "Try these exercises:\n",
    "1. Add more features to Titanic (Embarked, Cabin has_cabin, etc.)\n",
    "2. Try different thresholds and see effect on precision/recall\n",
    "3. Compare performance with/without feature scaling\n",
    "4. Build a logistic regression from scratch using gradient descent\n",
    "5. Try multi-class logistic regression on a different dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Summary\n",
    "\n",
    "Today you learned:\n",
    "- ‚úÖ Classification predicts categories, not numbers\n",
    "- ‚úÖ Sigmoid function converts numbers to probabilities\n",
    "- ‚úÖ Decision boundary separates classes (default threshold = 0.5)\n",
    "- ‚úÖ Confusion matrix shows all four outcomes (TP, TN, FP, FN)\n",
    "- ‚úÖ Accuracy: overall correctness\n",
    "- ‚úÖ Precision: avoid false positives\n",
    "- ‚úÖ Recall: catch all positives\n",
    "- ‚úÖ F1-Score: balance precision and recall\n",
    "- ‚úÖ ROC/AUC: performance across all thresholds\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Choose metrics based on business problem\n",
    "- Accuracy fails with imbalanced data\n",
    "- Threshold tuning is powerful\n",
    "- Always visualize confusion matrix\n",
    "- Feature engineering matters!\n",
    "\n",
    "**Tomorrow:** Support Vector Machines! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
